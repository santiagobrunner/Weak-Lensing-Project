{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408ab9c8",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc460e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some packages\n",
    "import matplotlib.pyplot as plt\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from MMD_functions import *\n",
    "\n",
    "# load the catalogue\n",
    "catalogue1000 = np.load('catalogue_1000sqd.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd08d24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 64 # HEALPix nside parameter\n",
    "\n",
    "cl_kappa_225 = np.loadtxt('cl_kappa_mean_225.txt')[:,1]\n",
    "cl_kappa_225 = np.concatenate((np.zeros(2), cl_kappa_225)) # add zeros for monopole and dipole\n",
    "kappamap_225 = hp.synfast(cl_kappa_225, nside)\n",
    "print(\"Cl_kappa225 shape:\", cl_kappa_225.shape, \"   kappamap225 shape:\", kappamap_225.shape )\n",
    "pixscale = 0.263\n",
    "sizes_in_arcsec1000 = catalogue1000['r50'] * pixscale   #arcsec\n",
    "print( \"\\nrange of DEC of catalogue1000:\")\n",
    "print(f\"[{min(catalogue1000['dec'])},{max(catalogue1000['dec'])}]\" )\n",
    "print( \"\\nrange of RA of catalogue1000:\")\n",
    "print(f\"[{min(catalogue1000['ra'])},{max(catalogue1000['ra'])}]\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e155519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert galaxy coordinates to HEALPix pixel indices\n",
    "galaxy_pix1000= hp.ang2pix(nside, catalogue1000['ra'], catalogue1000['dec'], lonlat=True)\n",
    "galaxy_pix1000_unique, galaxy_pix1000_counts = np.unique(galaxy_pix1000, return_counts=True)\n",
    "n_pixels = hp.nside2npix(nside)\n",
    "\n",
    "print(\"Galaxy pixels:\",galaxy_pix1000, \"   Length of Galaxy pixels(should match nr. of galaxies):\", len(galaxy_pix1000))\n",
    "print(\"Total number of galaxies:\", len(catalogue1000))\n",
    "print(\"Total number of pixels:\", n_pixels)\n",
    "print(\"Number of unique pixels with galaxies:\", len(galaxy_pix1000_unique))\n",
    "print(\"Max number of galaxies in a pixel:\", np.max(galaxy_pix1000_counts))\n",
    "print(\"Min number of galaxies in a pixel:\", np.min(galaxy_pix1000_counts))\n",
    "print(\"Mean number of galaxies in a pixel:\", np.mean(galaxy_pix1000_counts))\n",
    "print(\"Number of pixels with > 20'000 galaxies:\", np.sum(galaxy_pix1000_counts >= 20000))\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsic_size1000 = sizes_in_arcsec1000\n",
    "observed_size1000 = sizes_in_arcsec1000 * (1.0 + kappamap_225[galaxy_pix1000])\n",
    "\n",
    "size_mask = (intrinsic_size1000 < 5.0) #arcsec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49fb27e",
   "metadata": {},
   "source": [
    "### Computing and Plotting the mean of each pixel\n",
    "This is the most basic statistical measure, so we want to see, if we get a clear signal here.\n",
    "\n",
    "Thresholds/Constraints from Noah's report:\n",
    "- 20'000 galaxies per pixel for nside=64\n",
    "- nside=64: In this case, the avg number of galaxies is above the needed threshold\n",
    "- Outliers/Size threshold for too large galaxies: 5arcsec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac19fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply intrinsic size mask \n",
    "size_mask = (intrinsic_size1000 < 5.0) #arcsec\n",
    "\n",
    "galaxy_pix1000_masked = galaxy_pix1000[size_mask]\n",
    "intrinsic_size1000_masked = intrinsic_size1000[size_mask]\n",
    "observed_size1000_masked = intrinsic_size1000_masked* (1.0 + kappamap_225[galaxy_pix1000_masked])\n",
    "galaxy_pix1000_unique_masked, galaxy_pix1000_counts_masked = np.unique(galaxy_pix1000_masked, return_counts=True)\n",
    "\n",
    "print(\"Summary after applying size cut of 5 arcsec:\")\n",
    "print(\"Galaxy pixels:\",galaxy_pix1000_masked, \"   Length of Galaxy pixels(should match nr. of galaxies):\", len(galaxy_pix1000_masked))\n",
    "print(\"Total number of galaxies:\", len(intrinsic_size1000_masked))\n",
    "print(\"Total number of pixels:\", n_pixels)\n",
    "print(\"Number of unique pixels with galaxies:\", len(galaxy_pix1000_unique_masked))\n",
    "print(\"Max number of galaxies in a pixel:\", np.max(galaxy_pix1000_counts_masked))\n",
    "print(\"Min number of galaxies in a pixel:\", np.min(galaxy_pix1000_counts_masked))\n",
    "print(\"Mean number of galaxies in a pixel:\", np.mean(galaxy_pix1000_counts_masked))\n",
    "print(\"Number of pixels with > 20'000 galaxies:\", np.sum(galaxy_pix1000_counts_masked >= 20000))\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_unlensed = []\n",
    "means_lensed = []\n",
    "pixels = []\n",
    "\n",
    "\n",
    "for p in galaxy_pix1000_unique_masked:\n",
    "    mask = (galaxy_pix1000_masked == p)\n",
    "    if sum(mask) > 20000:   # Only consider pixels with more than 20'000 galaxies\n",
    "        means_unlensed.append(np.mean(intrinsic_size1000_masked[mask]))\n",
    "        means_lensed.append(np.mean(observed_size1000_masked[mask]))\n",
    "        pixels.append(p)\n",
    "\n",
    "means_unlensed = np.array(means_unlensed)\n",
    "means_lensed = np.array(means_lensed)\n",
    "# np.save(\"means_unlensed_1000sqd.npy\", means_unlensed)\n",
    "# np.save(\"means_lensed_1000sqd.npy\", means_lensed)\n",
    "# np.save(\"pixels_1000sqd.npy\", np.array(pixels))\n",
    "\n",
    "# means_lensed = np.load(\"means_lensed_1000sqd.npy\")\n",
    "# means_unlensed = np.load(\"means_unlensed_1000sqd.npy\")\n",
    "# pixels = np.load(\"pixels_1000sqd.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d45072",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_theory = np.mean(intrinsic_size1000)*(1.0 + kappamap_225[pixels]) \n",
    "m, b = np.polyfit(kappamap_225[pixels], means_lensed,1)\n",
    "print(\"Fit parameters (m,b):\", m, b)\n",
    "print(\"Mean intrinsic size:\", np.mean(intrinsic_size1000))\n",
    "# MMD^2 = (mean_pixel - mean_global)^2\n",
    "mmd2_lensed_linear_exakt = (means_lensed - np.mean(observed_size1000_masked))**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9fb051",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(kappamap_225[pixels], means_unlensed, '.', label='Unlensed')\n",
    "plt.plot(kappamap_225[pixels], means_lensed, '.', label='Lensed')\n",
    "plt.plot(kappamap_225[pixels], mean_theory, '--', color='g', label=r'theory $[\\theta_{obs}=\\theta_{intr}(1+\\kappa)]$')\n",
    "plt.plot(kappamap_225[pixels], m*kappamap_225[pixels]+b, '--', color='black', label='fit')\n",
    "plt.plot([np.min(kappamap_225[pixels]),np.max(kappamap_225[pixels])],[np.mean(intrinsic_size1000), np.mean(intrinsic_size1000)], '--', color='grey', label='mean intrinsic size')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$\\kappa$')\n",
    "plt.ylabel('Mean size [arcsec]')\n",
    "plt.title('Mean sizes in pixels with > 20\\'000 galaxies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welche Pixel müssten noch ein Minuszeichen beim MMD erhalten?\n",
    "\n",
    "plus_min_mask = (means_lensed - np.mean(observed_size1000_masked)) < 0  # 0 = positive, 1 = negative\n",
    "plus_min_mask = (-2) * plus_min_mask.astype(int) + 1    # 1 = positive, -1 = negative\n",
    "plus_min_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b9cb67",
   "metadata": {},
   "source": [
    "### Now use the MMD (linear kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b73b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE IMPLEMENTATION OF MMD FOR DIFFERENT KERNELS ---------------------------------\n",
    "def compute_mmd(X, Y, kernel):\n",
    "    \"\"\"\n",
    "    Compute Maximum Mean Discrepancy (MMD) between samples X and Y using a provided kernel.\n",
    "    \n",
    "    Parameters:\n",
    "        X: array-like, shape (n_samples_X, n_features)\n",
    "        Y: array-like, shape (n_samples_Y, n_features)\n",
    "        kernel: callable, must support signature kernel(X, Y), returns kernel matrix\n",
    "        \n",
    "    Returns:\n",
    "        mmd2: float, MMD^2 value\n",
    "    \"\"\"\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    m = X.shape[0]\n",
    "    n = Y.shape[0]\n",
    "    \n",
    "    K_XX = kernel(X, X)\n",
    "    K_YY = kernel(Y, Y)\n",
    "    K_XY = kernel(X, Y)\n",
    "    \n",
    "    # Remove diagonal for unbiased estimator\n",
    "    # np.fill_diagonal(K_XX, 0)\n",
    "    # np.fill_diagonal(K_YY, 0)\n",
    "    \n",
    "    mmd2 = (K_XX.sum() / (m * m)) \\\n",
    "        + (K_YY.sum() / (n * n)) \\\n",
    "        - (2 * K_XY.sum() / (m * n))\n",
    "    \n",
    "    return mmd2\n",
    "\n",
    "def compute_mmd_subsample(X, Y, kernel, size_X=1000, size_Y=1000, n_iter=10, random_state=None):\n",
    "    \"\"\"\n",
    "    Compute MMD between large X and Y by random subsampling.\n",
    "    Parameters:\n",
    "        X: array-like (N_X, features), large dataset\n",
    "        Y: array-like (N_Y, features), large dataset\n",
    "        kernel: callable kernel (scikit-learn compatible)\n",
    "        size_X: int, subsample size from X\n",
    "        size_Y: int, subsample size from Y\n",
    "        n_iter: int, number of repetitions\n",
    "        random_state: int or None, reproducibility\n",
    "    Returns:\n",
    "        avg_mmd: float, average MMD over n_iter subsamples\n",
    "        mmd_values: list of individual MMD values\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    mmd_values = []\n",
    "    for i in range(n_iter):\n",
    "        Xs = rng.choice(X, size_X, replace=False)\n",
    "        Ys = rng.choice(Y, size_Y, replace=False)\n",
    "        mmd = compute_mmd(Xs, Ys, kernel)\n",
    "        mmd_values.append(mmd)\n",
    "    return np.mean(mmd_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe513aa0",
   "metadata": {},
   "source": [
    "Wir lassen mal für alle pixels mit > 20'000 Galaxien die MMD berechnen mit Linear Kernel. Es sollte ein paar Stunden dauern aber wir erwarten die gleichen Ergebnisse wie beim Mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a74c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd2_lensed_linear_kernel = []\n",
    "Y_lensed = observed_size1000_masked.reshape(-1,1)\n",
    "for p in pixels:\n",
    "    mask = (galaxy_pix1000_masked==p)\n",
    "    if mask.sum()>20000:\n",
    "        X = observed_size1000_masked[mask].reshape(-1,1)\n",
    "        mmd2_lensed_linear_kernel.append(compute_mmd_subsample(X, Y_lensed, linear_kernel, 20000,20000,5,42))\n",
    "\n",
    "mmd2_lensed_linear_kernel= np.array(mmd2_lensed_linear_kernel)\n",
    "# np.save(\"MMD2_lensed_linear_kernel\",mmd2_lensed_linear_kernel)\n",
    "# mmd2_lensed_linear_kernel = np.load(\"MMD2_lensed_linear_kernel.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(kappamap_225[pixels]**2, mmd2_lensed_linear_kernel, '.', label='Lensed (Linear kernel)', alpha=0.3)\n",
    "plt.plot(kappamap_225[pixels]**2, mmd2_lensed_linear_exakt, '.', label=r'Lensed $(mean_{pixel} - mean_{global})^2$', alpha=0.3)\n",
    "plt.xlabel(r'$\\kappa^2$')\n",
    "plt.ylabel(r'$MMD^2$(linear kernel)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6fc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = kappamap_225[pixels]**2\n",
    "y = mmd2_lensed_linear_exakt\n",
    "# y = mmd2_lensed_linear_kernel\n",
    "\n",
    "n_bins = 24\n",
    "bins = np.linspace(x.min(), x.max(), n_bins + 1)\n",
    "\n",
    "# bin indices in [0, n_bins-1]\n",
    "idx = np.digitize(x, bins) - 1\n",
    "idx = np.clip(idx, 0, n_bins - 1)\n",
    "\n",
    "bin_centers = 0.5*(bins[1:] + bins[:-1])\n",
    "\n",
    "means = np.full(n_bins, np.nan)\n",
    "stds  = np.full(n_bins, np.nan)\n",
    "counts = np.zeros(n_bins, dtype=int)\n",
    "\n",
    "for i in range(n_bins):\n",
    "    m = (idx == i)\n",
    "    c = m.sum()\n",
    "    counts[i] = c\n",
    "    # print(f\"Bin {i}: count = {c}\")\n",
    "    if c >= 1:\n",
    "        means[i] = y[m].mean()\n",
    "    if c >= 2:\n",
    "        stds[i] = y[m].std(ddof=1)\n",
    "\n",
    "ses = np.where(counts >= 2, stds / np.sqrt(counts), np.nan)\n",
    "\n",
    "# keep only well-populated bins\n",
    "min_count = 5\n",
    "mask = (counts >= min_count) & np.isfinite(means)\n",
    "xc, yc, sec = bin_centers[mask], means[mask], ses[mask]\n",
    "\n",
    "# (optional) weighted fit (weights ~ 1/SE^2)\n",
    "w = np.where(np.isfinite(sec) & (sec > 0), 1.0/sec**2, 1.0)\n",
    "fit_params_linear, cov_linear = np.polyfit(xc, yc, 1, w=w, cov=True)   # FRAGE : MIT ODER OHNE GEWICHTUNG?\n",
    "print(f\"MMD² ≈ {fit_params_linear[0]:.3e} * κ² + {fit_params_linear[1]:.3e}\")\n",
    "\n",
    "plt.errorbar(xc, yc, yerr=sec, fmt='o', capsize=3)\n",
    "plt.plot(bin_centers, fit_params_linear[0]*bin_centers + fit_params_linear[1], 'r--', label='fit')\n",
    "plt.xlabel(r'$\\kappa^2$'); plt.ylabel(r'$\\mathrm{MMD}^2$ (linear kernel)')\n",
    "plt.title('Binned MMD² vs κ² (linspace)')\n",
    "plt.plot(x,y, '.', alpha=0.1)\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that plots the binned plots\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def plot_binned_MMD2(kappa_squared= True,y = mmd2_lensed_linear_exakt, binning_method = 'lin'):\n",
    "    # y = mmd2_lensed_linear_exakt\n",
    "    # y = mmd2_lensed_list\n",
    "    if kappa_squared:\n",
    "        x = kappamap_225[pixels]**2\n",
    "    else:\n",
    "        x = kappamap_225[pixels]\n",
    "    \n",
    "    n_bins = 24\n",
    "    if binning_method == 'lin':\n",
    "        bins = np.linspace(x.min(), x.max(), n_bins + 1)\n",
    "        title_str = 'linspace'\n",
    "    elif binning_method == 'log':\n",
    "        bins = np.logspace(np.log10(x.min() + 1e-8), np.log10(x.max()), n_bins + 1)\n",
    "        title_str = 'logspace'\n",
    "    elif binning_method == 'quantile':\n",
    "        bins = np.quantile(x, np.linspace(0, 1, n_bins + 1))\n",
    "        bins[0] -= 1e-12  # include min\n",
    "        title_str = 'quantile'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid binning method. Choose 'lin', 'log', or 'quantile'.\") \n",
    "    \n",
    "    idx = np.digitize(x, bins) - 1\n",
    "    idx = np.clip(idx, 0, n_bins - 1)   \n",
    "\n",
    "    bin_centers = 0.5*(bins[1:] + bins[:-1])\n",
    "    means = np.full(n_bins, np.nan)\n",
    "    stds  = np.full(n_bins, np.nan)\n",
    "    counts = np.zeros(n_bins, dtype=int)\n",
    "    for i in range(n_bins):\n",
    "        m = (idx == i)\n",
    "        c = m.sum()\n",
    "        counts[i] = c\n",
    "        if c >= 1:\n",
    "            means[i] = y[m].mean()\n",
    "        if c >= 2:\n",
    "            stds[i] = y[m].std(ddof=1)\n",
    "        \n",
    "    ses = np.where(counts >= 2, stds / np.sqrt(counts), np.nan)\n",
    "\n",
    "    # keep only well-populated bins\n",
    "    min_count = 5\n",
    "    mask = (counts >= min_count) & np.isfinite(means)\n",
    "    xc, yc, sec = bin_centers[mask], means[mask], ses[mask]\n",
    "\n",
    "    # (optional) weighted fit (weights ~ 1/SE^2)\n",
    "    w = np.where(np.isfinite(sec) & (sec > 0), 1.0/sec**2, 1.0)\n",
    "    if kappa_squared:\n",
    "        title = rf'Binned MMD² vs $\\kappa^2$ ({title_str} bins)'\n",
    "        slope, intercept = np.polyfit(xc, yc, 1, w=w)\n",
    "        print(f\"MMD² ≈ {slope:.3e} * κ² + {intercept:.3e}\")\n",
    "        plt.plot(bin_centers, slope*bin_centers + intercept, 'r--', label='fit')\n",
    "    else:\n",
    "        title = rf'Binned MMD² vs $\\kappa$ ({title_str} bins)'\n",
    "        a2, a1, a0 = np.polyfit(xc, yc, 2, w=w)\n",
    "        print(f\"MMD² ≈ {a2:.3e} * κ² + {a1:.3e} * κ + {a0:.3e}\")\n",
    "        plt.plot(bin_centers, a2*bin_centers**2 + a1*bin_centers + a0, 'r--', label='parabola fit')\n",
    "\n",
    "        #b=0:\n",
    "        model_even = lambda kappa, a, c: a * (kappa**2) + c\n",
    "\n",
    "        popt, pcov = curve_fit(model_even, xc[mask], yc[mask])  # honors sigma as true SE\n",
    "        a, c = popt\n",
    "        a_err, c_err = np.sqrt(np.diag(pcov))\n",
    "        print(f\"MMD² ≈ {a:.3e} κ² + {c:.3e}  (± {a_err:.1e}, {c_err:.1e})\")\n",
    "        plt.plot(bin_centers, model_even(bin_centers, a, c), 'g--', label=r'$ax^2 + c$ fit')\n",
    "\n",
    "    plt.errorbar(xc, yc, yerr=sec, fmt='o', capsize=3)\n",
    "    plt.xlabel(rf'$\\kappa^2$'); plt.ylabel(r'$\\mathrm{MMD}^2$ (linear kernel)')\n",
    "    plt.title(title)\n",
    "    # plt.xlim(0, 0.0001)\n",
    "    plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed63fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_binned_MMD2(kappa_squared=True, y=mmd2_lensed_linear_exakt, binning_method='lin')\n",
    "plot_binned_MMD2(kappa_squared=True, y=mmd2_lensed_linear_kernel, binning_method='lin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e7752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binned_MMD_signed(x, y, binning_method = 'lin', n_bins=24, show=True):\n",
    "    \n",
    "    if binning_method == 'lin':\n",
    "        bins = np.linspace(x.min(), x.max(), n_bins + 1)\n",
    "        title_str = 'linspace'\n",
    "    elif binning_method == 'log':\n",
    "        bins = np.logspace(np.log10(x.min() + 1e-8), np.log10(x.max()), n_bins + 1)\n",
    "        title_str = 'logspace'\n",
    "    elif binning_method == 'quantile':\n",
    "        bins = np.quantile(x, np.linspace(0, 1, n_bins + 1))\n",
    "        bins[0] -= 1e-12  # include min\n",
    "        title_str = 'quantile'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid binning method. Choose 'lin', 'log', or 'quantile'.\")\n",
    "    \n",
    "    idx = np.digitize(x, bins) - 1\n",
    "    idx = np.clip(idx, 0, n_bins - 1)\n",
    "\n",
    "    bin_centers = 0.5*(bins[1:] + bins[:-1])\n",
    "\n",
    "    means = np.full(n_bins, np.nan)\n",
    "    stds= np.full(n_bins, np.nan)\n",
    "    counts = np.zeros(n_bins, dtype=int)\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        m = (idx == i)\n",
    "        c = m.sum()\n",
    "        counts[i] = c\n",
    "        if c >= 1:\n",
    "            means[i] = y[m].mean()\n",
    "            \n",
    "        if c >= 2:\n",
    "            stds[i] = y[m].std(ddof=1)\n",
    "\n",
    "\n",
    "    # keep only well-populated bins\n",
    "    min_count = 5\n",
    "    mask = counts >= min_count\n",
    "\n",
    "    ses = np.where(counts >= 2, stds / np.sqrt(counts), np.nan)\n",
    "    xc, yc, sec = bin_centers[mask], means[mask], ses[mask]\n",
    "\n",
    "\n",
    "    # Weighted fit (weights ~ 1/SE^2)\n",
    "    w = np.where(np.isfinite(sec) & (sec > 0), 1.0/sec**2, 1.0)\n",
    "    slope, intercept = np.polyfit(xc, yc, 1, w=w)\n",
    "    print(f\"MMD ≈ {slope:.3e} * κ + {intercept:.3e}\")\n",
    "    plt.plot(bin_centers, slope*bin_centers + intercept, 'r--', label='Weighted Fit Exakt MMD')\n",
    "\n",
    "    plt.errorbar(xc, yc, yerr=sec, fmt='o', capsize=3, label='Exakt MMD $(\\mu_{pix} - \\mu_{glob})$')\n",
    "    plt.xlabel(r'$\\kappa$'); plt.ylabel(r'$\\mathrm{MMD}$ (linear kernel)')\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    title = rf'Binned signed MMD vs $\\kappa$ ({title_str} bins)'\n",
    "    plt.title(title)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return  xc, yc, sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee0f70",
   "metadata": {},
   "source": [
    "### Noise Level with exakt linear Kernel\n",
    "Get noise level:\n",
    "We get many MMDs between random samples, take their mean and std and plot it as a horizontal band. If our signal is outside of this band, we know it is a real singal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd2_noise = []\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "size = 20000  # match your per-pixel (or subsample) size\n",
    "for _ in range(15000):\n",
    "    # Xs = rng.choice(observed_size1000_masked, size=size, replace=False)\n",
    "    # Ys = rng.choice(observed_size1000_masked, size=size, replace=False)\n",
    "\n",
    "    Xs = rng.choice(observed_size1000_masked, size=size, replace=True)\n",
    "    Ys = rng.choice(observed_size1000_masked, size=size, replace=True)\n",
    "    mmd2_noise.append( (Xs.mean() - Ys.mean())**2 )\n",
    "\n",
    "mmd2_noise = np.array(mmd2_noise)\n",
    "noise_mean = mmd2_noise.mean()\n",
    "noise_std  = mmd2_noise.std()\n",
    "\n",
    "\n",
    "print(\"noise mean:\", noise_mean, r\"$\\pm$\", noise_std  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "\n",
    "plt.errorbar(xc, yc, yerr=sec, fmt='.', capsize=3, label=r'Exakt MMD $(\\mu_{pix} - \\mu_{glob})^2$', color='blue')\n",
    "plt.plot(bin_centers, fit_params_linear[0]*bin_centers + fit_params_linear[1], 'r--', label=r'Weighted Fit Exakt: MMD$^2$={:.2e}$\\cdot\\kappa^2$ + {:.2e}'.format(fit_params_linear[0], fit_params_linear[1]))\n",
    "plt.axhline(noise_mean, color='black', linestyle='--', label='Noise Mean')\n",
    "plt.fill_between([0,0.0007], \n",
    "                 noise_mean - noise_std, \n",
    "                 noise_mean + noise_std,\n",
    "                 color='black', alpha=0.5, label='Noise ±1σ')\n",
    "plt.xlim(0, 0.0004)\n",
    "plt.legend()\n",
    "plt.xlabel(r'$\\kappa^2$'); plt.ylabel(r'$\\mathrm{MMD}^2$ (linear kernel)')\n",
    "plt.title('Binned MMD² vs κ² (linspace)')\n",
    "\n",
    "ax = plt.gca()\n",
    "fmt = ScalarFormatter(useMathText=True)\n",
    "fmt.set_powerlimits((0, 0))         # always use scientific notation\n",
    "ax.xaxis.set_major_formatter(fmt)\n",
    "ax.ticklabel_format(axis='x', style='sci', scilimits=(0, 0), useMathText=False)\n",
    "ax.ticklabel_format(useOffset=True) # keep the scientific scale as an offset text\n",
    "plt.plot(x,y, '.', alpha=0.1)\n",
    "plt.ylim(-0.000005, 0.00015)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/MMD2_vs_kappa2_linear.jpg', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "slope, intercept = fit_params_linear\n",
    "slope_err, intercept_err = np.sqrt(np.diag(cov_linear))\n",
    "print(f\"Final fit result: MMD² ≈ ({slope:.3e} ± {slope_err:.1e}) * κ² + ({intercept:.3e} ± {intercept_err:.1e})\")\n",
    "\n",
    "yc_preds = slope*xc + intercept\n",
    "r2 = r2_score(yc, yc_preds)\n",
    "print(f\"R² of the fit: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the kappa² limit where MMD² rises above noise + 1σ\n",
    "\n",
    "kappa2_noise_threshold = np.linspace(0.00001, 0.00005, 50)\n",
    "mmd2_noise_threshold = fit_params_linear[0]*kappa2_noise_threshold + fit_params_linear[1]\n",
    "\n",
    "above_noise = mmd2_noise_threshold > (noise_mean + noise_std)\n",
    "kappa2_limit = kappa2_noise_threshold[above_noise][0]\n",
    "\n",
    "print(f\"Kappa² limit where MMD² rises above noise + 1σ: {kappa2_limit:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce04779",
   "metadata": {},
   "source": [
    "### Finer Convergence map\n",
    "Now we want to apply a finer/smoother convergence map to the galaxies. We will then compute the MMD of the coarser pixels, such that each bigger pixel represents a neighbourhood of galaxies with slightly different kappas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a smoother convergence map.\n",
    "# From now on, we only use the big catalogue\n",
    "nside_fine = 1024\n",
    "\n",
    "kappamap_fine = hp.synfast( cl_kappa_225, nside_fine)\n",
    "print(hp.nside2npix(nside_fine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8904e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert galaxy coordinates to pixel numbers in the finer map\n",
    "gal_pix_fine = hp.ang2pix(nside_fine, catalogue1000['ra'], catalogue1000['dec'], lonlat=True)\n",
    "gal_pix_fine_unique, gal_pix_fine_counts = np.unique(gal_pix_fine, return_counts=True)\n",
    "\n",
    "print(\"Galaxy pixels:\",gal_pix_fine, \"   Length of Galaxy pixels(should match nr. of galaxies):\", len(gal_pix_fine))\n",
    "print(\"Number of unique pixels with galaxies:\", len(gal_pix_fine_unique))\n",
    "print(\"Max number of galaxies in a pixel:\", np.max(gal_pix_fine_counts))\n",
    "print(\"Min number of galaxies in a pixel:\", np.min(gal_pix_fine_counts))\n",
    "print(\"Mean number of galaxies in a pixel:\", np.mean(gal_pix_fine_counts))\n",
    "print(\"Number of pixels with > 20'000 galaxies:\", np.sum(gal_pix_fine_counts >= 20000))\n",
    "print('-'*30)\n",
    "\n",
    "\n",
    "# Compute observed sizes for all galaxies using the finer kappa map\n",
    "observed_size_fine = intrinsic_size1000 * (1.0 + kappamap_fine[gal_pix_fine])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38231d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd2_lensed_rbf_fine_batch1 = np.load(f\"mmd2_lensed_rbf_fine/mmd2_lensed_rbf_fine_batch_1.npy\")\n",
    "mmd2_lensed_rbf_fine_batch2 = np.load(f\"mmd2_lensed_rbf_fine/mmd2_lensed_rbf_fine_batch_2.npy\")\n",
    "mmd2_lensed_rbf_fine_batch3 = np.load(f\"mmd2_lensed_rbf_fine/mmd2_lensed_rbf_fine_batch_3.npy\")\n",
    "mmd2_lensed_rbf_fine_batch4 = np.load(f\"mmd2_lensed_rbf_fine/mmd2_lensed_rbf_fine_batch_4.npy\")\n",
    "mmd2_lensed_rbf_fine_batch5 = np.load(f\"mmd2_lensed_rbf_fine/mmd2_lensed_rbf_fine_batch_5.npy\")\n",
    "mmd2_lensed_rbf_fine_batch6 = np.load(f\"mmd2_lensed_rbf_fine/mmd2_lensed_rbf_fine_batch_6.npy\")\n",
    "mmd2_lensed_rbf_fine_batch7 = np.load(f\"mmd2_lensed_rbf_fine/mmd2_lensed_rbf_fine_batch_7.npy\")\n",
    "mmd2_lensed_rbf_fine_batch8 = np.load(f\"mmd2_lensed_rbf_fine/mmd2_lensed_rbf_fine_batch_8.npy\")\n",
    "mmd2_lensed_rbf_fine_batch9 = np.load(f\"mmd2_lensed_rbf_fine/mmd2_lensed_rbf_fine_batch_9.npy\")\n",
    "mmd2_lensed_rbf_fine_batch10 = np.load(f\"mmd2_lensed_rbf_fine/mmd2_lensed_rbf_fine_batch_10.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappamap_avg_fine = np.load('kappa_avg_fine.npy')\n",
    "mmd2_rbf_noise_fine = np.load('mmd2_rbf_noise.npy')\n",
    "mmd2_rbf_noise_mean_fine = np.mean(mmd2_rbf_noise_fine)\n",
    "mmd2_rbf_noise_std_fine = np.std(mmd2_rbf_noise_fine, ddof=1)\n",
    "\n",
    "mmd2_lensed_rbf_fine = np.concatenate((mmd2_lensed_rbf_fine_batch1, mmd2_lensed_rbf_fine_batch2,\n",
    "                                       mmd2_lensed_rbf_fine_batch3, mmd2_lensed_rbf_fine_batch4,\n",
    "                                       mmd2_lensed_rbf_fine_batch5, mmd2_lensed_rbf_fine_batch6,\n",
    "                                       mmd2_lensed_rbf_fine_batch7, mmd2_lensed_rbf_fine_batch8,\n",
    "                                       mmd2_lensed_rbf_fine_batch9, mmd2_lensed_rbf_fine_batch10), axis=0)\n",
    "\n",
    "mask_20k_gals = galaxy_pix1000_counts >= 20000  # pixels with at least 20k galaxies\n",
    "kappamap_avg_fine = kappamap_avg_fine[mask_20k_gals]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 24\n",
    "bins = np.linspace(np.min(kappamap_avg_fine**2), np.max(kappamap_avg_fine**2), n_bins + 1)\n",
    "\n",
    "# bin indices in [0, n_bins-1]\n",
    "idx = np.digitize(kappamap_avg_fine**2, bins) - 1\n",
    "idx = np.clip(idx, 0, n_bins - 1)\n",
    "\n",
    "bin_centers = 0.5*(bins[1:] + bins[:-1])\n",
    "\n",
    "means = np.full(n_bins, np.nan)\n",
    "stds  = np.full(n_bins, np.nan)\n",
    "counts = np.zeros(n_bins, dtype=int)\n",
    "\n",
    "for i in range(n_bins):\n",
    "    m = (idx == i)\n",
    "    c = m.sum()\n",
    "    counts[i] = c\n",
    "    # print(f\"Bin {i}: count = {c}\")\n",
    "    if c >= 1:\n",
    "        means[i] = mmd2_lensed_rbf_fine[m].mean()\n",
    "    if c >= 2:\n",
    "        stds[i] = mmd2_lensed_rbf_fine[m].std(ddof=1)\n",
    "\n",
    "print(\"COUNTS:\", counts)\n",
    "ses = np.where(counts >= 2, stds / np.sqrt(counts), np.nan)\n",
    "\n",
    "# keep only well-populated bins\n",
    "min_count = 5\n",
    "mask = (counts >= min_count) & np.isfinite(means)\n",
    "xc, yc, sec = bin_centers[mask], means[mask], ses[mask]\n",
    "\n",
    "# (optional) weighted fit (weights ~ 1/SE^2)\n",
    "w = np.where(np.isfinite(sec) & (sec > 0), 1.0/sec**2, 1.0)\n",
    "slope, intercept = np.polyfit(xc, yc, 1, w=w)   # FRAGE : MIT ODER OHNE GEWICHTUNG?\n",
    "print(f\"MMD² ≈ {slope:.3e} * κ² + {intercept:.3e}\")\n",
    "\n",
    "plt.plot(kappamap_avg_fine**2, mmd2_lensed_rbf_fine, '.', label='Lensed (MMD RBF)', alpha=0.2)\n",
    "\n",
    "plt.errorbar(xc, yc, yerr=sec, fmt='o', capsize=3)\n",
    "plt.plot(bin_centers, slope*bin_centers + intercept, 'r--', label='Weighted Fit')\n",
    "plt.xlabel(r'$\\bar{\\kappa}^2$'); plt.ylabel(r'$\\mathrm{MMD}^2$ (RBF kernel)')\n",
    "plt.axhline(mmd2_rbf_noise_mean_fine, color='black', linestyle='--', label='Noise Mean')\n",
    "plt.fill_between([0,0.0007], \n",
    "                 mmd2_rbf_noise_mean_fine - mmd2_rbf_noise_std_fine, \n",
    "                 mmd2_rbf_noise_mean_fine + mmd2_rbf_noise_std_fine,\n",
    "                 color='black', alpha=0.5, label='Noise ±1σ')\n",
    "plt.title(r'Binned MMD² vs $\\bar{\\kappa}²$ (linspace)')\n",
    "# plt.ylim(0.0001, 0.000125)\n",
    "plt.xlim(np.min(bins)-1e-5, np.max(bins))\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "print(xc)\n",
    "print(yc)\n",
    "print(mmd2_rbf_noise_mean_fine + mmd2_rbf_noise_std_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_fine = []\n",
    "for pix in galaxy_pix1000_unique_masked:\n",
    "    mask = (galaxy_pix1000 == pix)\n",
    "    if sum(mask) > 20000:\n",
    "        means_fine.append(np.mean(observed_size_fine[mask]))\n",
    "\n",
    "means_fine = np.array(means_fine)\n",
    "plus_min_mask_fine = np.sign(means_fine - intrinsic_size1000_masked.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffccc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_fine = np.sign(means_fine - observed_size1000_masked.mean())\n",
    "print(sign_fine)\n",
    "plus_min_mask_fine = sign_fine > 0\n",
    "print(plus_min_mask_fine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e685d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def binning_and_plotting(x,y, n_bins = 24, Title: str = None, plot=True):\n",
    "    bins = np.linspace(x.min(), x.max(), n_bins + 1)\n",
    "\n",
    "    # bin indices in [0, n_bins-1]\n",
    "    idx = np.digitize(x, bins) - 1\n",
    "    idx = np.clip(idx, 0, n_bins - 1)\n",
    "    bin_centers = 0.5*(bins[1:] + bins[:-1])\n",
    "\n",
    "    means = np.full(n_bins, np.nan)\n",
    "    stds  = np.full(n_bins, np.nan)\n",
    "    counts = np.zeros(n_bins, dtype=int)\n",
    "    for i in range(n_bins):\n",
    "        m = (idx == i)\n",
    "        c = m.sum()\n",
    "        counts[i] = c\n",
    "        # print(f\"Bin {i}: count = {c}\")\n",
    "        if c >= 1:\n",
    "            means[i] = y[m].mean()\n",
    "        if c >= 2:\n",
    "            stds[i] = y[m].std(ddof=1)\n",
    "\n",
    "\n",
    "    # keep only well-populated bins\n",
    "    min_count = 5\n",
    "    mask = counts >= min_count\n",
    "\n",
    "    ses = np.where(counts >= 2, stds / np.sqrt(counts), np.nan)\n",
    "    xc, yc, sec = bin_centers[mask], means[mask], ses[mask]\n",
    "\n",
    "    # (optional) weighted fit (weights ~ 1/SE^2)\n",
    "    w = np.where(np.isfinite(sec) & (sec > 0), 1.0/sec**2, 1.0)\n",
    "    fit_params, cov = np.polyfit(xc, yc, 1, w=w, cov=True)\n",
    "    print(f\"MMD ≈ {fit_params[0]:.3e} * κ + {fit_params[1]:.3e}\")\n",
    "    if not plot:\n",
    "        return xc, yc, sec, fit_params\n",
    "    else:\n",
    "        # plt.figure()\n",
    "        plt.plot(x,y, '.', label=r'MMD$^2$ per Pixel', alpha=0.2)\n",
    "        plt.errorbar(xc, yc, yerr=sec, fmt='o', capsize=3)\n",
    "        # plt.plot(bin_centers, fit_params[0]*bin_centers + fit_params[1], 'r--', label='fit')\n",
    "        # plt.xlabel(r'$\\kappa$'); plt.ylabel(r'$\\mathrm{MMD}$ (RBF kernel)')\n",
    "        plt.title(Title if not Title is None else ' ')\n",
    "        \n",
    "        # plt.legend(); plt.show()\n",
    "\n",
    "    return  xc, yc, sec, fit_params, cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fab17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign_fine = plus_min_mask_fine\n",
    "plus_min_mask_fine = sign_fine < 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397d886",
   "metadata": {},
   "source": [
    "### Recovering the Convergence Map and Power Spectrum\n",
    "We create a new convergence map. Apply it to the intrinsic galaxy sizes and compute the MMD just as before. We compute the MMD with rbf and custom kernel. Then use the estimators we obtained with the earlier kappamap_fine to try to recover the kappa values of the new convergence map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b310f",
   "metadata": {},
   "source": [
    "#### RBF Kernel\n",
    "We recover the convergence map (seed=31) from the MMD measurements with the RBFkernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d07247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and apply new convergence map for RECOVERY test\n",
    "recovery_rand_seed = 31\n",
    "np.random.seed(recovery_rand_seed)\n",
    "recovery_kappamap = hp.synfast(cl_kappa_225, nside_fine)\n",
    "recovery_observed_size = intrinsic_size1000 * (1.0 + recovery_kappamap[gal_pix_fine])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_recov_fine = []\n",
    "for pix in galaxy_pix1000_unique:\n",
    "    mask = (galaxy_pix1000 == pix)\n",
    "    if sum(mask) > 20000:\n",
    "        means_recov_fine.append(np.mean(recovery_observed_size[mask]))\n",
    "\n",
    "means_recov_fine = np.array(means_recov_fine)\n",
    "sign_recov_fine = np.sign(means_recov_fine - recovery_observed_size.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd2_recov_rbf_batch1 = np.load(f\"mmd2_recov_rbf/mmd2_lensed_rbf_fine_batch_1.npy\")\n",
    "mmd2_recov_rbf_batch2 = np.load(f\"mmd2_recov_rbf/mmd2_lensed_rbf_fine_batch_2.npy\")\n",
    "mmd2_recov_rbf_batch3 = np.load(f\"mmd2_recov_rbf/mmd2_lensed_rbf_fine_batch_3.npy\")\n",
    "mmd2_recov_rbf_batch4 = np.load(f\"mmd2_recov_rbf/mmd2_lensed_rbf_fine_batch_4.npy\")\n",
    "mmd2_recov_rbf_batch5 = np.load(f\"mmd2_recov_rbf/mmd2_lensed_rbf_fine_batch_5.npy\")\n",
    "mmd2_recov_rbf_batch6 = np.load(f\"mmd2_recov_rbf/mmd2_lensed_rbf_fine_batch_6.npy\")\n",
    "mmd2_recov_rbf_batch7 = np.load(f\"mmd2_recov_rbf/mmd2_lensed_rbf_fine_batch_7.npy\")\n",
    "mmd2_recov_rbf_batch8 = np.load(f\"mmd2_recov_rbf/mmd2_lensed_rbf_fine_batch_8.npy\")\n",
    "mmd2_recov_rbf_batch9 = np.load(f\"mmd2_recov_rbf/mmd2_lensed_rbf_fine_batch_9.npy\")\n",
    "mmd2_recov_rbf_batch10 = np.load(f\"mmd2_recov_rbf/mmd2_lensed_rbf_fine_batch_10.npy\")\n",
    "\n",
    "mmd2_recov_rbf = np.concatenate((mmd2_recov_rbf_batch1, mmd2_recov_rbf_batch2,\n",
    "                                 mmd2_recov_rbf_batch3, mmd2_recov_rbf_batch4,\n",
    "                                 mmd2_recov_rbf_batch5, mmd2_recov_rbf_batch6,\n",
    "                                 mmd2_recov_rbf_batch7, mmd2_recov_rbf_batch8,\n",
    "                                 mmd2_recov_rbf_batch9, mmd2_recov_rbf_batch10), axis=0)\n",
    "kappa_recov_avg_fine = np.load('kappa_recov_avg_fine.npy')\n",
    "kappa_recov_avg_fine = kappa_recov_avg_fine[mask_20k_gals]      # Want to predict these kappa values\n",
    "\n",
    "signed_kappa2_recov = np.sign(kappa_recov_avg_fine) * kappa_recov_avg_fine**2   # Correct sign assignments: 887/1145\n",
    "signed_mmd2_recov_rbf = sign_recov_fine * mmd2_recov_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "recov_xc, recov_yc, recov_sec, recov_fit, cov_fit = binning_and_plotting(signed_kappa2_recov, signed_mmd2_recov_rbf, n_bins=24, Title=r'Binned MMD² vs $sgn(\\kappa)\\cdot\\kappa²$ (Recovery Map)', plot=True)\n",
    "plt.plot(np.linspace(-0.0004, 0.0004, 10), recov_fit[0]*np.linspace(-0.0004, 0.0004, 10) + recov_fit[1], linestyle='--', color='black', label=r'Weighted fit: MMD={:.2e}$\\cdot\\kappa$ + {:.2e}'.format(recov_fit[0], recov_fit[1]))\n",
    "\n",
    "plt.xlabel(r'$sgn(\\kappa)\\cdot\\kappa²$')\n",
    "plt.ylabel(r'$MMD²$ (RBF kernel)')\n",
    "plt.title(r'Binned MMD² vs $sgn(\\kappa)\\cdot\\kappa^2$ (RBF)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/recovery_mmd2_vs_kappa2_rbf.jpg', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "slope, intercept = recov_fit\n",
    "slope_unc, intercept_unc = np.sqrt(np.diag(cov_fit))\n",
    "\n",
    "print(f\"Slope: {slope} ± {slope_unc}\")\n",
    "print(f\"Intercept: {intercept} ± {intercept_unc}\")\n",
    "\n",
    "recov_yc_preds = slope * recov_xc + intercept\n",
    "r2_recov = r2_score(recov_yc, recov_yc_preds)\n",
    "print(f\"R² score for recovery fit: {r2_recov:.4f}\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e41d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kappa_recov = np.empty_like(kappa_recov_avg_fine)  # Thats the vector we want to fill with predicted kappa values\n",
    "\n",
    "\n",
    "pred_kappa2_recov_pos = signed_mmd2_recov_rbf[signed_mmd2_recov_rbf > 0] / estimator_pos[0] - estimator_pos[1]/estimator_pos[0]     # Problem: not all values are positive because of wrong sign assignment\n",
    "pred_kappa2_recov_neg = signed_mmd2_recov_rbf[signed_mmd2_recov_rbf < 0] / estimator_neg[0] - estimator_neg[1]/estimator_neg[0]\n",
    "\n",
    "pred_kappa_recov[signed_mmd2_recov_rbf > 0] = np.sign(pred_kappa2_recov_pos) * np.sqrt(np.abs(pred_kappa2_recov_pos))\n",
    "# pred_kappa_recov[signed_mmd2_recov_rbf < 0] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590bc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.sign(pred_kappa2_recov_pos) == np.sign(signed_mmd2_recov_rbf[signed_mmd2_recov_rbf>0])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3c22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((-1==np.sign(pred_kappa2_recov_neg)).sum())\n",
    "print(np.sign(pred_kappa2_recov_neg).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeafbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pred_kappa2_recov_pos, signed_kappa2_recov[signed_mmd2_recov_rbf > 0], '.', alpha=0.2, label='Recovered Positive MMD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50149999",
   "metadata": {},
   "source": [
    "#### Directed RBF Kernel\n",
    "Now we do the same as above, but with the MMDs measured with the custom directed RBF kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f182f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd2_recov_dir_rbf_batch1 = np.load(f\"mmd2_recov_dir_rbf/mmd2_lensed_dir_rbf_fine_batch_1.npy\")\n",
    "mmd2_recov_dir_rbf_batch2 = np.load(f\"mmd2_recov_dir_rbf/mmd2_lensed_dir_rbf_fine_batch_2.npy\")\n",
    "mmd2_recov_dir_rbf_batch3 = np.load(f\"mmd2_recov_dir_rbf/mmd2_lensed_dir_rbf_fine_batch_3.npy\")\n",
    "mmd2_recov_dir_rbf_batch4 = np.load(f\"mmd2_recov_dir_rbf/mmd2_lensed_dir_rbf_fine_batch_4.npy\")\n",
    "mmd2_recov_dir_rbf_batch5 = np.load(f\"mmd2_recov_dir_rbf/mmd2_lensed_dir_rbf_fine_batch_5.npy\")\n",
    "mmd2_recov_dir_rbf_batch6 = np.load(f\"mmd2_recov_dir_rbf/mmd2_lensed_dir_rbf_fine_batch_6.npy\")\n",
    "mmd2_recov_dir_rbf_batch7 = np.load(f\"mmd2_recov_dir_rbf/mmd2_lensed_dir_rbf_fine_batch_7.npy\")\n",
    "mmd2_recov_dir_rbf_batch8 = np.load(f\"mmd2_recov_dir_rbf/mmd2_lensed_dir_rbf_fine_batch_8.npy\")\n",
    "mmd2_recov_dir_rbf_batch9 = np.load(f\"mmd2_recov_dir_rbf/mmd2_lensed_dir_rbf_fine_batch_9.npy\")\n",
    "mmd2_recov_dir_rbf_batch10 = np.load(f\"mmd2_recov_dir_rbf/mmd2_lensed_dir_rbf_fine_batch_10.npy\")\n",
    "\n",
    "mmd2_recov_dir_rbf_fine = np.concatenate((mmd2_recov_dir_rbf_batch1, mmd2_recov_dir_rbf_batch2,\n",
    "                                           mmd2_recov_dir_rbf_batch3, mmd2_recov_dir_rbf_batch4,\n",
    "                                           mmd2_recov_dir_rbf_batch5, mmd2_recov_dir_rbf_batch6,\n",
    "                                           mmd2_recov_dir_rbf_batch7, mmd2_recov_dir_rbf_batch8,\n",
    "                                           mmd2_recov_dir_rbf_batch9, mmd2_recov_dir_rbf_batch10), axis=0)\n",
    "mmd2_recov_dir_rbf_fine = (-1) * mmd2_recov_dir_rbf_fine  # Correct sign convention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a23be",
   "metadata": {},
   "outputs": [],
   "source": [
    "recov_dir_xc, recov_dir_yc, recov_dir_sec, recov_dir_fit, cov_dir_fit = binning_and_plotting(signed_kappa2_recov, mmd2_recov_dir_rbf_fine, n_bins=24, Title=r'Binned MMD² vs $sgn(\\kappa)\\cdot\\kappa²$ (Recovery Map, Directional RBF)', plot=True)\n",
    "plt.plot(np.linspace(-0.0004, 0.0004, 10), recov_dir_fit[0]*np.linspace(-0.0004, 0.0004, 10) + recov_dir_fit[1], linestyle='--', color='black', label=r'Weighted fit: MMD^2={:.2e}$\\cdot\\kappa^2$ + {:.2e}'.format(recov_dir_fit[0], recov_dir_fit[1]))\n",
    "plt.xlabel(r'$sgn(\\kappa)\\cdot\\kappa²$')\n",
    "plt.ylabel(r'$MMD²$ (Dir. RBF kernel)')\n",
    "plt.title('Binned MMD² vs $sgn(\\kappa)\\cdot\\kappa²$ (Directional RBF)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/recovery_mmd2_vs_kappa2_directional_rbf.jpg\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "slope, intercept = recov_dir_fit\n",
    "slope_unc, intercept_unc = np.sqrt(np.diag(cov_dir_fit))\n",
    "\n",
    "print(f\"Slope: {slope} ± {slope_unc}\")\n",
    "print(f\"Intercept: {intercept} ± {intercept_unc}\")\n",
    "\n",
    "\n",
    "recov_dir_yc_preds = slope * recov_dir_xc + intercept\n",
    "r2_recov_dir = r2_score(recov_dir_yc, recov_dir_yc_preds)\n",
    "print(f\"R² score for recovery fit: {r2_recov_dir:.4f}\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93ade9",
   "metadata": {},
   "source": [
    "### Create a new estimator\n",
    "What we will do here:\n",
    "- On euler, we will create a new fine convergence map kappa_est_fine. (set random seed)!\n",
    "- We will apply this convergence to the intrinsic sizes\n",
    "- compute the MMD^2 between coarse pixel and global distribution\n",
    "- compute the average kappa in each coarse pixel\n",
    "\n",
    "- Upload here the kappa_avg_est and MMD2_rbf_est\n",
    "- compute mean-shift\n",
    "- Plot as above sgn(kappa)*kappa^2 vs +/- MMD2 (the sign of the MMD is given by mean-shift)\n",
    "- Fit the binned values and get an estimator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b006f4",
   "metadata": {},
   "source": [
    "#### Directed RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd2_dir_rbf_fine_batch1 = np.load(f\"mmd2_dir_rbf_fine3/mmd2_dir_rbf_fine_batch_1.npy\")\n",
    "mmd2_dir_rbf_fine_batch2 = np.load(f\"mmd2_dir_rbf_fine3/mmd2_dir_rbf_fine_batch_2.npy\")\n",
    "mmd2_dir_rbf_fine_batch3 = np.load(f\"mmd2_dir_rbf_fine3/mmd2_dir_rbf_fine_batch_3.npy\")\n",
    "mmd2_dir_rbf_fine_batch4 = np.load(f\"mmd2_dir_rbf_fine3/mmd2_dir_rbf_fine_batch_4.npy\")\n",
    "mmd2_dir_rbf_fine_batch5 = np.load(f\"mmd2_dir_rbf_fine3/mmd2_dir_rbf_fine_batch_5.npy\")\n",
    "mmd2_dir_rbf_fine_batch6 = np.load(f\"mmd2_dir_rbf_fine3/mmd2_dir_rbf_fine_batch_6.npy\")\n",
    "mmd2_dir_rbf_fine_batch7 = np.load(f\"mmd2_dir_rbf_fine3/mmd2_dir_rbf_fine_batch_7.npy\")\n",
    "mmd2_dir_rbf_fine_batch8 = np.load(f\"mmd2_dir_rbf_fine3/mmd2_dir_rbf_fine_batch_8.npy\")\n",
    "mmd2_dir_rbf_fine_batch9 = np.load(f\"mmd2_dir_rbf_fine3/mmd2_dir_rbf_fine_batch_9.npy\")\n",
    "mmd2_dir_rbf_fine_batch10 = np.load(f\"mmd2_dir_rbf_fine3/mmd2_dir_rbf_fine_batch_10.npy\")\n",
    "\n",
    "mmd2_dir_rbf_fine = np.concatenate((mmd2_dir_rbf_fine_batch1, mmd2_dir_rbf_fine_batch2,\n",
    "                                    mmd2_dir_rbf_fine_batch3, mmd2_dir_rbf_fine_batch4,\n",
    "                                    mmd2_dir_rbf_fine_batch5, mmd2_dir_rbf_fine_batch6,\n",
    "                                    mmd2_dir_rbf_fine_batch7, mmd2_dir_rbf_fine_batch8,\n",
    "                                    mmd2_dir_rbf_fine_batch9, mmd2_dir_rbf_fine_batch10), axis=0)\n",
    "kappa_avg_fine4 = np.load('kappa_avg_fine4.npy')\n",
    "kappa_avg_fine4 = kappa_avg_fine4[mask_20k_gals]\n",
    "\n",
    "signed_kappa2_avg_fine4 = np.sign(kappa_avg_fine4) * kappa_avg_fine4**2\n",
    "mmd2_dir_rbf_fine = (-1) * mmd2_dir_rbf_fine  # Correct sign convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "((np.sign(mmd2_dir_rbf_fine)== np.sign(signed_kappa2_avg_fine4)).sum())/len(mmd2_dir_rbf_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "fig2.patch.set_facecolor(bg_color)\n",
    "est_dir_xc, est_dir_yc, est_sec, est_dir_fit, est_cov_fit = binning_and_plotting(signed_kappa2_avg_fine4, mmd2_dir_rbf_fine, n_bins=24, Title=r'Binned MMD$^2$ vs $sgn(\\kappa)\\cdot\\kappa^2$ (Directed RBF)', plot=True)\n",
    "plt.plot(np.linspace(-0.0004, 0.0004, 10), est_dir_fit[0]*np.linspace(-0.0004, 0.0004, 10) + est_dir_fit[1], linestyle='--', color='black', label='Weighted fit')\n",
    "# plt.plot(np.linspace(-0.0004, 0.0004, 10), a*np.linspace(-0.0004, 0.0004, 10) + b, linestyle='--', color='Green', label=r'Weighted fit: MMD^2={:.2e}$\\cdot\\kappa^2$ + {:.2e}'.format(a, b))\n",
    "plt.xlabel(r'$sgn(\\kappa)\\cdot\\kappa^2$', fontsize=18)\n",
    "plt.ylabel(r'$MMD^2$', fontsize=18)\n",
    "plt.title(r'Directed RBF', fontsize=20)\n",
    "plt.legend(loc='upper left', fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"images/estimator_mmd2_vs_kappa2_dir_rbf.jpg\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "slope, intercept = est_dir_fit\n",
    "slope_unc, intercept_unc = np.sqrt(np.diag(est_cov_fit))\n",
    "\n",
    "print(f\"Slope: {slope} ± {slope_unc}\")\n",
    "print(f\"Intercept: {intercept} ± {intercept_unc}\")\n",
    "est_dir_yc_preds = slope * est_dir_xc + intercept\n",
    "r2_est_dir = r2_score(est_dir_yc, est_dir_yc_preds)\n",
    "print(f\"R² score for estimation fit: {r2_est_dir:.4f}\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.polyfit(signed_kappa2_avg_fine4, mmd2_dir_rbf_fine, 1)\n",
    "print(f\"MMD² ≈ {a:.3e} * κ² + {b:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a4d05",
   "metadata": {},
   "source": [
    "#### RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_seed = 19\n",
    "np.random.seed(estimator_seed)\n",
    "estimator_kappamap = hp.synfast(cl_kappa_225, nside_fine)\n",
    "estimator_observed_size = intrinsic_size1000 * (1.0 + estimator_kappamap[gal_pix_fine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d943efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dfd90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_est_fine = []\n",
    "for pix in galaxy_pix1000_unique:\n",
    "    mask = (galaxy_pix1000 == pix)\n",
    "    if sum(mask) > 20000:\n",
    "        means_est_fine.append(np.mean(estimator_observed_size[mask]))\n",
    "\n",
    "means_est_fine = np.array(means_est_fine)\n",
    "sign_est_fine = np.sign(means_est_fine - estimator_observed_size.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86682e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd2_est_rbf_fine_batch1 = np.load(f\"mmd2_est_rbf_fine2/mmd2_est_rbf_fine_batch_1.npy\")\n",
    "mmd2_est_rbf_fine_batch2 = np.load(f\"mmd2_est_rbf_fine2/mmd2_est_rbf_fine_batch_2.npy\")\n",
    "mmd2_est_rbf_fine_batch3 = np.load(f\"mmd2_est_rbf_fine2/mmd2_est_rbf_fine_batch_3.npy\")\n",
    "mmd2_est_rbf_fine_batch4 = np.load(f\"mmd2_est_rbf_fine2/mmd2_est_rbf_fine_batch_4.npy\")\n",
    "mmd2_est_rbf_fine_batch5 = np.load(f\"mmd2_est_rbf_fine2/mmd2_est_rbf_fine_batch_5.npy\")\n",
    "mmd2_est_rbf_fine_batch6 = np.load(f\"mmd2_est_rbf_fine2/mmd2_est_rbf_fine_batch_6.npy\")\n",
    "mmd2_est_rbf_fine_batch7 = np.load(f\"mmd2_est_rbf_fine2/mmd2_est_rbf_fine_batch_7.npy\")\n",
    "mmd2_est_rbf_fine_batch8 = np.load(f\"mmd2_est_rbf_fine2/mmd2_est_rbf_fine_batch_8.npy\")\n",
    "mmd2_est_rbf_fine_batch9 = np.load(f\"mmd2_est_rbf_fine2/mmd2_est_rbf_fine_batch_9.npy\")\n",
    "mmd2_est_rbf_fine_batch10 = np.load(f\"mmd2_est_rbf_fine2/mmd2_est_rbf_fine_batch_10.npy\")\n",
    "\n",
    "mmd2_est_rbf_fine = np.concatenate((mmd2_est_rbf_fine_batch1, mmd2_est_rbf_fine_batch2,\n",
    "                                    mmd2_est_rbf_fine_batch3, mmd2_est_rbf_fine_batch4,\n",
    "                                    mmd2_est_rbf_fine_batch5, mmd2_est_rbf_fine_batch6,\n",
    "                                    mmd2_est_rbf_fine_batch7, mmd2_est_rbf_fine_batch8,\n",
    "                                    mmd2_est_rbf_fine_batch9, mmd2_est_rbf_fine_batch10), axis=0)\n",
    "\n",
    "kappa_est_avg_fine3 = np.load('kappa_avg_fine4.npy')\n",
    "kappa_est_avg_fine3 = kappa_est_avg_fine3[mask_20k_gals]\n",
    "\n",
    "signed_kappa2_est_fine3 = np.sign(kappa_est_avg_fine3) * kappa_est_avg_fine3**2\n",
    "signed_mmd2_est_rbf = sign_est_fine * mmd2_est_rbf_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "((sign_est_fine == np.sign(kappa_est_avg_fine3)).sum())/len(sign_est_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315bb077",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "est_rbf_xc, est_rbf_yc, est_rbf_sec, est_rbf_fit, est_rbf_cov_fit = binning_and_plotting(signed_kappa2_est_fine3, signed_mmd2_est_rbf, n_bins=24, Title=r'Binned MMD² vs $sgn(\\kappa)\\cdot\\kappa^2$ (Estimation Map, RBF)', plot=True)\n",
    "plt.plot(np.linspace(-0.0004, 0.0004, 10), est_rbf_fit[0]*np.linspace(-0.0004, 0.0004, 10) + est_rbf_fit[1], linestyle='--', color='black', label='Weighted fit')\n",
    "plt.xlabel(r'$sgn(\\kappa)\\cdot\\kappa^2$', fontsize=18)\n",
    "plt.ylabel(r'$MMD^2$', fontsize=18)\n",
    "plt.title(r'RBF Kernel', fontsize=20)\n",
    "plt.tight_layout()\n",
    "# plt.xlim(-0.0006, 0.00045)\n",
    "# plt.savefig(\"images/estimator_mmd2_vs_kappa2_rbf.jpg\", dpi=300)\n",
    "# plt.plot(np.linspace(-0.0004, 0.0004, 10), a2*np.linspace(-0.0004, 0.0004, 10) + b2, linestyle='--', color='Green', label=r'Weighted fit: MMD^2={:.2e}$\\cdot\\kappa^2$ + {:.2e}'.format(a2, b2))\n",
    "plt.legend(loc='upper left', fontsize=12)\n",
    "bg_color = '#F7F7F7'\n",
    "fig.patch.set_facecolor(bg_color)\n",
    "plt.show()\n",
    "\n",
    "slope, intercept = est_rbf_fit\n",
    "slope_unc, intercept_unc = np.sqrt(np.diag(est_rbf_cov_fit))\n",
    "\n",
    "print(f\"Slope: {slope} ± {slope_unc}\")\n",
    "print(f\"Intercept: {intercept} ± {intercept_unc}\")\n",
    "est_rbf_yc_preds = slope * est_rbf_xc + intercept\n",
    "r2_est_rbf = r2_score(est_rbf_yc, est_rbf_yc_preds)\n",
    "print(f\"R² score for estimation fit: {r2_est_rbf:.4f}\"  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40103311",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2, b2 = np.polyfit(signed_kappa2_est_fine3, signed_mmd2_est_rbf, 1)\n",
    "print(f\"MMD² ≈ {a2:.3e} * κ² + {b2:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ca53f",
   "metadata": {},
   "source": [
    "### Actual Recovery of the Convergence Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d2a8f5",
   "metadata": {},
   "source": [
    "#### Pixelwise recovery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1931b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kappa2_dir_rbf = mmd2_recov_dir_rbf_fine/est_dir_fit[0] - est_dir_fit[1]/est_dir_fit[0]\n",
    "pred_kappa_dir_rbf = np.sign(pred_kappa2_dir_rbf) * np.sqrt(np.abs(pred_kappa2_dir_rbf))\n",
    "\n",
    "pred_kappa2_rbf = signed_mmd2_recov_rbf/est_rbf_fit[0] - est_rbf_fit[1]/est_rbf_fit[0]\n",
    "pred_kappa_rbf = np.sign(pred_kappa2_rbf) * np.sqrt(np.abs(pred_kappa2_rbf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "def plot_pixel_level_results(kappa_true, kappa_pred):\n",
    "    \"\"\"Generate all pixel-level validation figures\"\"\"\n",
    "    \n",
    "    mask = ~(np.isnan(kappa_true) | np.isnan(kappa_pred))\n",
    "    kt, kp = np.asarray(kappa_true)[mask], np.asarray(kappa_pred)[mask]\n",
    "    residuals = kp - kt\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle('Pixel-Level Results (Dir. RBF)', fontsize=16)\n",
    "    # 1. Scatter plot\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.scatter(kt, kp, alpha=0.3, s=5)\n",
    "    lims = [min(kt.min(), kp.min()), max(kt.max(), kp.max())]\n",
    "    ax1.plot(lims, lims, 'r--', lw=2)\n",
    "    ax1.set_xlabel(r'$\\kappa_{\\rm true}$')\n",
    "    ax1.set_ylabel(r'$\\kappa_{\\rm pred}$')\n",
    "    ax1.set_title(f'r = {np.corrcoef(kt, kp)[0,1]:.3f}')\n",
    "    \n",
    "    # 2. Residual histogram\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.hist(residuals, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "    x = np.linspace(residuals.min(), residuals.max(), 200)\n",
    "    ax2.plot(x, stats.norm.pdf(x, np.mean(residuals), np.std(residuals)), 'r-', lw=2)\n",
    "    ax2.axvline(0, color='k', linestyle='--')\n",
    "    ax2.set_xlabel(r'$\\kappa_{\\rm pred} - \\kappa_{\\rm true}$')\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.set_title(f'Mean = {np.mean(residuals):.2e}, Std = {np.std(residuals):.4f}')\n",
    "    \n",
    "    # 3. Residuals vs true kappa\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.scatter(kt, residuals, alpha=0.3, s=5)\n",
    "    ax3.axhline(0, color='r', linestyle='--')\n",
    "    ax3.set_xlabel(r'$\\kappa_{\\rm true}$')\n",
    "    ax3.set_ylabel(r'$\\kappa_{\\rm pred} - \\kappa_{\\rm true}$')\n",
    "    ax3.set_title('Residuals vs true convergence')\n",
    "    print(\"Residuals > 0:\", (residuals > 0).sum(), \"Residuals < 0:\", (residuals < 0).sum())\n",
    "    print(\"Residuals vs kapp correlation coeff. :\", np.corrcoef(kt, residuals)[0,1])\n",
    "    # 4. Summary statistics text\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    rmse = np.sqrt(np.mean(residuals**2))\n",
    "    r2 = 1 - np.sum(residuals**2) / np.sum((kt - np.mean(kt))**2)\n",
    "    nrmse = rmse / np.std(kt)\n",
    "    \n",
    "    stats_text = f\"\"\"\n",
    "    Pixel-Level Summary Statistics\n",
    "    {'='*35}\n",
    "    \n",
    "    N pixels:           {len(kt)}\n",
    "    \n",
    "    Pearson r:          {np.corrcoef(kt, kp)[0,1]:.4f}\n",
    "    R²:                 {r2:.4f}\n",
    "    \n",
    "    RMSE:               {rmse:.6f}\n",
    "    NRMSE (σ):          {nrmse:.4f}\n",
    "    \n",
    "    Mean residual:      {np.mean(residuals):.2e}\n",
    "    Std residual:       {np.std(residuals):.6f}\n",
    "    \"\"\"\n",
    "    ax4.text(0.1, 0.5, stats_text, fontsize=14, family='monospace',\n",
    "             verticalalignment='center', transform=ax4.transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pixel_level_results(kappa_recov_avg_fine, pred_kappa_rbf)\n",
    "# plt.savefig(\"images/pixel_level_results_rbf.jpg\", dpi=300)\n",
    "plot_pixel_level_results(kappa_recov_avg_fine, pred_kappa_dir_rbf)\n",
    "# plt.savefig(\"images/pixel_level_results_dir_rbf.jpg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1cbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residual_map(kappa_true, kappa_pred, galaxy_pix_unique, nside=64, \n",
    "                      save_path='residual_map.pdf'):\n",
    "    \"\"\"\n",
    "    Create a HEALPix map showing spatial distribution of residuals.\n",
    "    \n",
    "    Parameters:\n",
    "        kappa_true: array of true convergence values per pixel\n",
    "        kappa_pred: array of predicted convergence values per pixel\n",
    "        galaxy_pix_unique: array of pixel indices corresponding to kappa values\n",
    "        nside: HEALPix nside parameter\n",
    "        save_path: path to save the figure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute residuals\n",
    "    residuals = kappa_pred - kappa_true\n",
    "    \n",
    "    # Create empty HEALPix map (filled with NaN for empty pixels)\n",
    "    npix = hp.nside2npix(nside)\n",
    "    residual_map = np.full(npix, np.nan)\n",
    "    \n",
    "    # Fill in the residuals for pixels with data\n",
    "    residual_map[galaxy_pix_unique] = residuals\n",
    "    \n",
    "    # Find the center of your observed patch\n",
    "    # Get RA, Dec of pixels with data\n",
    "    theta, phi = hp.pix2ang(nside, galaxy_pix_unique)\n",
    "    ra = np.degrees(phi)\n",
    "    dec = 90 - np.degrees(theta)\n",
    "    \n",
    "    # Center coordinates (mean of your data)\n",
    "    ra_center = np.mean(ra)\n",
    "    dec_center = np.mean(dec)\n",
    "    \n",
    "    # Determine color scale limits (symmetric around zero)\n",
    "    vmax = np.nanmax(np.abs(residuals))\n",
    "    vmin = -vmax\n",
    "    \n",
    "    # Create the plot - use cartview for rectangular projection\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    hp.cartview(residual_map, \n",
    "                title=r'Residual Map: $\\kappa_{\\rm pred} - \\kappa_{\\rm true}$',\n",
    "                cmap='RdBu_r',\n",
    "                min=vmin,\n",
    "                max=vmax,\n",
    "                lonra=[ra_center - 20, ra_center + 20],  # ±20 degrees\n",
    "                latra=[dec_center - 20, dec_center + 20],\n",
    "                cbar=True,\n",
    "                unit=r'$\\Delta\\kappa$',\n",
    "                hold=True)\n",
    "    \n",
    "    # hp.graticule()\n",
    "    \n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Residual map saved to {save_path}\")\n",
    "    \n",
    "    return fig, residual_map\n",
    "\n",
    "\n",
    "def plot_kappa_comparison_maps(kappa_true, kappa_pred, galaxy_pix_unique, \n",
    "                               nside=64, save_path='kappa_comparison.pdf'):\n",
    "    \"\"\"\n",
    "    Create three side-by-side HEALPix maps: true, predicted, and residuals.\n",
    "    \"\"\"\n",
    "    \n",
    "    npix = hp.nside2npix(nside)\n",
    "    \n",
    "    # Create maps\n",
    "    true_map = np.full(npix, np.nan)\n",
    "    pred_map = np.full(npix, np.nan)\n",
    "    residual_map = np.full(npix, np.nan)\n",
    "    \n",
    "    true_map[galaxy_pix_unique] = kappa_true\n",
    "    pred_map[galaxy_pix_unique] = kappa_pred\n",
    "    residual_map[galaxy_pix_unique] = kappa_pred - kappa_true\n",
    "    \n",
    "    # Find center of observed patch\n",
    "    theta, phi = hp.pix2ang(nside, galaxy_pix_unique)\n",
    "    ra = np.degrees(phi)\n",
    "    dec = 90 - np.degrees(theta)\n",
    "    ra_center = 0 #np.mean(ra)\n",
    "    dec_center = 0 #np.mean(dec)\n",
    "    \n",
    "    # Determine color scales\n",
    "    vmax_kappa = np.abs(kappa_true).max()       #max(np.nanmax(np.abs(kappa_true)), np.nanmax(np.abs(kappa_pred)))\n",
    "    vmin_kappa = -vmax_kappa\n",
    "    \n",
    "    vmax_res =  np.nanmax(np.abs(kappa_pred - kappa_true))\n",
    "    vmin_res = -vmax_res\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    fig.patch.set_facecolor(bg_color)\n",
    "    # True convergence\n",
    "    plt.subplot(131)\n",
    "    hp.cartview(true_map, \n",
    "                # title=r'$\\kappa_{\\rm true}$',\n",
    "                cmap='RdBu_r',\n",
    "                min=vmin_kappa,\n",
    "                max=vmax_kappa,\n",
    "                lonra=[-20, 20],\n",
    "                latra=[-20, 20],\n",
    "                hold=True,\n",
    "                sub=131)\n",
    "    plt.title(r'$\\kappa_{\\rm true}$', fontsize=24)\n",
    "    # hp.graticule()\n",
    "    \n",
    "    # Predicted convergence\n",
    "    plt.subplot(132)\n",
    "    hp.cartview(pred_map, \n",
    "                # title=r'$\\kappa_{\\rm pred}$',\n",
    "                cmap='RdBu_r',\n",
    "                min=vmin_kappa,\n",
    "                max=vmax_kappa,\n",
    "                lonra=[ra_center - 20, ra_center + 20],\n",
    "                latra=[dec_center - 20, dec_center + 20],\n",
    "                hold=True,\n",
    "                sub=132)\n",
    "    plt.title(r'$\\kappa_{\\rm pred}$', fontsize=24)\n",
    "    # hp.graticule()\n",
    "    \n",
    "    # Residuals\n",
    "    plt.subplot(133)\n",
    "    hp.cartview(residual_map, \n",
    "                # title=r'$\\kappa_{\\rm pred} - \\kappa_{\\rm true}$',\n",
    "                cmap='RdBu_r',\n",
    "                min=vmin_res,\n",
    "                max=vmax_res,\n",
    "                lonra=[ra_center - 20, ra_center + 20],\n",
    "                latra=[dec_center - 20, dec_center + 20],\n",
    "                hold=True,\n",
    "                sub=133)\n",
    "    plt.title(r'$\\kappa_{\\rm pred} - \\kappa_{\\rm true}$', fontsize=24)\n",
    "    # hp.graticule()\n",
    "    \n",
    "    # plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Comparison map saved to {save_path}\")\n",
    "    \n",
    "    return #fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default sizes for all plots\n",
    "# plt.rcParams['axes.titlesize'] = 24\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "# plt.rcParams['ytick.labelsize'] = 24\n",
    "plot_kappa_comparison_maps(kappa_recov_avg_fine, pred_kappa_rbf, galaxy_pix1000_unique[mask_20k_gals], nside=64, save_path='images/kappa_comparison_rbf.jpg')\n",
    "# plt.savefig('images/kappamap_comparison_rbf.jpg', dpi=300)\n",
    "plot_kappa_comparison_maps(kappa_recov_avg_fine, pred_kappa_dir_rbf, galaxy_pix1000_unique[mask_20k_gals], nside=64, save_path='images/kappa_comparison_directional_rbf.jpg')\n",
    "# plt.savefig('images/kappamap_comparison_dir_rbf.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92f45b",
   "metadata": {},
   "source": [
    "#### Recovery of Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"First, we compute the Gaussian statistics of the predicted field.\n",
    "This involves getting a zero-mean, comparing std, skewness kurtosis.\"\"\"\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def compute_gaussian_stats(kappa_field):\n",
    "    \"\"\"Compute mean, std, skewness, kurtosis of the kappa field.\"\"\"\n",
    "    \n",
    "    mean = np.nanmean(kappa_field)\n",
    "    std = np.nanstd(kappa_field)\n",
    "    skewness = skew(kappa_field, nan_policy='omit')\n",
    "    kurt = kurtosis(kappa_field, nan_policy='omit')\n",
    "    print(f\"MEAN = {mean:.4e}\", f\"\\nSTD = {std:.4e}\", f\"\\nSkewness = {skewness:.4e}\", f\"\\nKurtosis = {kurt:.4e}\")\n",
    "    print(\"-\"*20)\n",
    "    return mean#, std, skewness, kurt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb33e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gaussian_stats(pred_kappa_rbf)\n",
    "compute_gaussian_stats(pred_kappa_dir_rbf)\n",
    "compute_gaussian_stats(kappa_recov_avg_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['axes.titlesize'] = 24\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 8\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "fig.patch.set_facecolor(bg_color)\n",
    "plt.hist(kappa_recov_avg_fine, bins=80, density=True, alpha=0.6, label='True Kappa')\n",
    "plt.hist(pred_kappa_rbf, bins=80, density=True, alpha=0.5, label='Predicted RBF')\n",
    "plt.vlines(mean, ymin=0, ymax=80, color='black', linestyle='--', label='Predicted Mean', linewidth=2)\n",
    "# plt.hist(pred_kappa_dir_rbf, bins=100, density=True, alpha=0.5, label='Predicted Dir. RBF'\n",
    "plt.xlabel(r'$\\kappa$')\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/kappa_hist_rbf.jpg', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(kappa_recov_avg_fine, bins=80, density=True, alpha=0.6, label='True Kappa')\n",
    "plt.hist(pred_kappa_dir_rbf, bins=80, density=True, alpha=0.5, label='Predicted Dir. RBF')\n",
    "# plt.hist(pred_kappa_dir_rbf, bins=100, density=True, alpha=0.5, label='Predicted Dir. RBF'\n",
    "plt.xlabel(r'$\\kappa$')\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/kappa_hist_dir_rbf.jpg', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recov_random_seed = 31\n",
    "np.random.seed(recov_random_seed)\n",
    "recovery_kappamap = hp.synfast(cl_kappa_225, nside_fine)\n",
    "recovery_kappamap = hp.ud_grade(recovery_kappamap, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55935458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "import numpy as np\n",
    "\n",
    "pseudo_cl = np.loadtxt(\"pseudo_cl.txt\")\n",
    "\n",
    "full_map_rbf = np.zeros(hp.nside2npix(64))\n",
    "full_map_rbf[galaxy_pix1000_unique[mask_20k_gals]] = pred_kappa_rbf\n",
    "\n",
    "full_map_dir_rbf = np.zeros(hp.nside2npix(64))\n",
    "full_map_dir_rbf[galaxy_pix1000_unique[mask_20k_gals]] = pred_kappa_dir_rbf\n",
    "\n",
    "full_map_perf1 = np.zeros(hp.nside2npix(64))\n",
    "full_map_perf2 = np.zeros(hp.nside2npix(64))\n",
    "full_map_perf1[galaxy_pix1000_unique[mask_20k_gals]] = kappamap_225[galaxy_pix1000_unique[mask_20k_gals]]\n",
    "full_map_perf2[galaxy_pix1000_unique[mask_20k_gals]] = recovery_kappamap[galaxy_pix1000_unique[mask_20k_gals]]  # Perfect recovery\n",
    "\n",
    "# map: 1D array of convergence values, zeros where unobserved\n",
    "mean_subtracted_rbf = full_map_rbf - np.mean(full_map_rbf[full_map_rbf != 0])   #Remove monopole\n",
    "cls_raw_rbf = hp.anafast(mean_subtracted_rbf, lmax=256)\n",
    "f_sky_rbf = np.count_nonzero(mean_subtracted_rbf) / mean_subtracted_rbf.size\n",
    "print(f_sky_rbf)\n",
    "cls_corr_rbf = cls_raw_rbf / f_sky_rbf\n",
    "\n",
    "mean_subtracted_dir_rbf = full_map_dir_rbf - np.mean(full_map_dir_rbf[full_map_dir_rbf != 0])   #Remove monopole\n",
    "cls_raw_dir_rbf = hp.anafast(mean_subtracted_dir_rbf, lmax=256)\n",
    "f_sky_dir_rbf = np.count_nonzero(mean_subtracted_dir_rbf) / mean_subtracted_dir_rbf.size\n",
    "print(f_sky_dir_rbf)\n",
    "cls_corr_dir_rbf = cls_raw_dir_rbf / f_sky_dir_rbf\n",
    "\n",
    "mean_subtracted_perf = full_map_perf1 - np.mean(full_map_perf1[full_map_perf1 != 0])   #Remove monopole\n",
    "cls_raw_perf = hp.anafast(mean_subtracted_perf, lmax=256)\n",
    "f_sky_perf = np.count_nonzero(mean_subtracted_perf) / mean_subtracted_perf.size\n",
    "print(f_sky_perf)\n",
    "cls_corr_perf = cls_raw_perf / f_sky_perf\n",
    "\n",
    "mean_subtracted_perf2 = full_map_perf2 - np.mean(full_map_perf2[full_map_perf2 != 0])   #Remove monopole\n",
    "cls_raw_perf2 = hp.anafast(mean_subtracted_perf2, lmax=256)\n",
    "f_sky_perf2 = np.count_nonzero(mean_subtracted_perf2) / mean_subtracted_perf2.size\n",
    "print(f_sky_perf2)\n",
    "cls_corr_perf2 = cls_raw_perf2 / f_sky_perf2\n",
    "\n",
    "\n",
    "ell = np.arange(len(cls_corr_rbf))\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(cls_corr_rbf, label='Recovered Power Spectrum: RBF', color='blue')\n",
    "plt.plot(cls_corr_dir_rbf, label='Recovered Power Spectrum: Dir. RBF', color='orange')\n",
    "plt.plot(cls_corr_perf, label='Recovered Kappa Power Spectrum (Perfect)', color='purple')\n",
    "plt.plot(pseudo_cl, label=r'Pseudo Power Spectrum', color='red')\n",
    "plt.xlabel(r'$\\ell$')\n",
    "plt.ylabel(r'$C_\\ell$')\n",
    "plt.title('Angular Power Spectrum of Sky Patch')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-10, 3*1e-7)\n",
    "plt.xlim(2, 256)\n",
    "plt.grid(True, which='both')\n",
    "plt.tight_layout()\n",
    "plt.gca().set_aspect('auto', adjustable='box')\n",
    "plt.legend()\n",
    "# plt.savefig(\"images/power_spectrum_comparison.jpg\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e4ce4",
   "metadata": {},
   "source": [
    "### Create new galaxy distributions\n",
    "We assign each galaxy a new random pixel, such that they are placed somewhere else.\n",
    "Then, we create a new convergence map (new seed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_pix64 = galaxy_pix1000_unique\n",
    "possible_pix1024 = gal_pix_fine_unique\n",
    "# np.save('possible_pix64.npy', possible_pix64)\n",
    "# np.save('possible_pix1024.npy', possible_pix1024)\n",
    "\n",
    "possible_pix64.shape\n",
    "possible_pix1024.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5e2a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seed = 29\n",
    "np.random.seed(val_seed)\n",
    "val_galaxy_pix1000 = np.random.choice(possible_pix1024, size=galaxy_pix1000.size, replace=True)\n",
    "val_galaxy_pix1000_unique, val_galaxy_pix1000_counts = np.unique(val_galaxy_pix1000, return_counts=True)\n",
    "\n",
    "val_kappamap = hp.synfast(cl_kappa_225, nside_fine)\n",
    "val_observed_size = intrinsic_size1000 * (1.0 + val_kappamap[val_galaxy_pix1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f6b44",
   "metadata": {},
   "source": [
    "#### Recover convergence map with new galaxy distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seed = 29\n",
    "np.random.seed(val_seed)\n",
    "# Draw new random positions of the galaxies\n",
    "ra_max, ra_min = catalogue1000['ra'].max(), catalogue1000['ra'].min()\n",
    "dec_max, dec_min = catalogue1000['dec'].max(), catalogue1000['dec'].min()\n",
    "\n",
    "new_ra = np.random.uniform(ra_min, ra_max, size=catalogue1000.shape[0])\n",
    "new_dec = np.random.uniform(dec_min, dec_max, size=catalogue1000.shape[0])\n",
    "\n",
    "\n",
    "# Convert galaxy coordinates to HEALPix pixel indices\n",
    "galaxy_pix1000_val = hp.ang2pix(nside, new_ra, new_dec, lonlat=True)\n",
    "galaxy_pix1000_unique_val, galaxy_pix1000_counts_val = np.unique(galaxy_pix1000_val, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c31357",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_20k_gals_val = galaxy_pix1000_counts_val >= 20000\n",
    "mask_20k_gals_val.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_val_fine = np.load('mmd2_val_rbf/means_val_fine.npy')\n",
    "sign_val_fine = np.load('mmd2_val_rbf/sign_val_fine.npy')\n",
    "mmd2_val_rbf_batch1 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_1.npy\")\n",
    "mmd2_val_rbf_batch2 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_2.npy\")\n",
    "mmd2_val_rbf_batch3 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_3.npy\")\n",
    "mmd2_val_rbf_batch4 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_4.npy\")\n",
    "mmd2_val_rbf_batch5 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_5.npy\")\n",
    "mmd2_val_rbf_batch6 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_6.npy\")\n",
    "mmd2_val_rbf_batch7 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_7.npy\")\n",
    "mmd2_val_rbf_batch8 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_8.npy\")\n",
    "mmd2_val_rbf_batch9 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_9.npy\")\n",
    "mmd2_val_rbf_batch10 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_10.npy\")\n",
    "mmd2_val_rbf_batch11 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_11.npy\")\n",
    "mmd2_val_rbf_batch12 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_12.npy\")\n",
    "mmd2_val_rbf_batch13 = np.load(f\"mmd2_val_rbf/mmd2_val_rbf_fine_batch_13.npy\")\n",
    "\n",
    "mmd2_val_rbf = np.concatenate((mmd2_val_rbf_batch1, mmd2_val_rbf_batch2,\n",
    "                               mmd2_val_rbf_batch3, mmd2_val_rbf_batch4,\n",
    "                               mmd2_val_rbf_batch5, mmd2_val_rbf_batch6,\n",
    "                               mmd2_val_rbf_batch7, mmd2_val_rbf_batch8,\n",
    "                               mmd2_val_rbf_batch9, mmd2_val_rbf_batch10,\n",
    "                               mmd2_val_rbf_batch11, mmd2_val_rbf_batch12,\n",
    "                               mmd2_val_rbf_batch13), axis=0)\n",
    "kappa_val_avg_fine = np.load('mmd2_val_rbf/kappa_val_avg_fine_masked.npy')\n",
    "# mask_20k_gals_val = val_galaxy_pix1000_counts >= 20000\n",
    "# kappa_val_avg_fine = kappa_val_avg_fine[mask_20k_gals_val]\n",
    "\n",
    "\n",
    "signed_kappa2_val = np.sign(kappa_val_avg_fine) * kappa_val_avg_fine**2\n",
    "signed_mmd2_val_rbf = sign_val_fine * mmd2_val_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84038eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kappa2_val = signed_mmd2_val_rbf/est_rbf_fit[0] - est_rbf_fit[1]/est_rbf_fit[0]\n",
    "pred_kappa_val = np.sign(pred_kappa2_val) * np.sqrt(np.abs(pred_kappa2_val))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(signed_kappa2_val, pred_kappa2_val, '.', alpha=0.2)\n",
    "plt.axis('equal')\n",
    "x = np.array([-0.0004, 0.0004])\n",
    "plt.plot(x,x, 'b--', label='y=x')\n",
    "plt.legend()\n",
    "plt.xlabel(r'True $\\kappa^2$')\n",
    "plt.ylabel(r'Predicted $\\kappa^2$ (RBF)')\n",
    "plt.title('Predicted vs True $\\kappa^2$ on Validation Set (RBF)')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"images/val_predicted_vs_true_kappa2_rbf.jpg\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628afa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pixel_level_results(kappa_val_avg_fine, pred_kappa_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e810f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kappa_comparison_maps(kappa_val_avg_fine, pred_kappa_val, galaxy_pix1000_unique_val[mask_20k_gals_val], nside=64, save_path=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COSMO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
